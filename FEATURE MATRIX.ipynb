{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26f5b742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import math\n",
    "import time\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import progressbar\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a41627f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--suffix', type=str, default='SpdAclRp')  # using suffix, you can specify set of basic features to be used to create feature map\n",
    "args, unknown = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d038937a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data point of a trajectory\n",
    "class point:    \n",
    "    time = 0\n",
    "    lat = 0\n",
    "    lng = 0\n",
    "    speed = 0\n",
    "    acceleration = 0\n",
    "    rpm = 0\n",
    "    heading = 0\n",
    "    accelX = 0\n",
    "    accelY = 0\n",
    "    accelZ = 0\n",
    "    \n",
    "    def __init__(self, time, lat, lng, speed, acceleration, rpm, heading, accelX, accelY, accelZ):\n",
    "        self.time = time\n",
    "        self.lat = lat\n",
    "        self.lng = lng\n",
    "        self.speed = speed/3.6 #converting to m/s\n",
    "        self.acceleration = acceleration #reported in m/s^2\n",
    "        self.rpm = rpm #engine RPM\n",
    "        self.heading = heading #between 0 to 359\n",
    "        self.accelX = accelX\n",
    "        self.accelY = accelY\n",
    "        self.accelZ = accelZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c68c6b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnAngularDisplacement(fLat, fLon, sLat, sLon):\n",
    "    \n",
    "    \n",
    "    fLat = np.radians(float(fLat))\n",
    "    fLon = np.radians(float(fLon))\n",
    "    sLat = np.radians(float(sLat))\n",
    "    sLon = np.radians(float(sLon))\n",
    "    \n",
    "    dis = np.sqrt((fLat-sLat)**2 + (fLon-sLon)**2)\n",
    "    return dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f0e6bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversineDistance(aLat, aLng, bLat, bLng, metric='mi'):\n",
    "    #From degree to radian\n",
    "    fLat = math.radians(aLat)\n",
    "    fLon = math.radians(aLng)\n",
    "    sLat = math.radians(bLat)\n",
    "    sLon = math.radians(bLng)\n",
    "           \n",
    "    R = 3958.7564 #mi\n",
    "    \n",
    "    if metric == 'meters':\n",
    "        R = 6371000.0 #meters\n",
    "    elif metric == 'km':\n",
    "        R = 6371.0 #km\n",
    "    dLon = sLon - fLon\n",
    "    dLat = sLat - fLat\n",
    "    a = math.sin(dLat/2.0)**2 + (math.cos(fLat) * math.cos(sLat) * math.pow(math.sin(dLon/2.0), 2))\n",
    "    c = 2.0 * math.atan2(math.sqrt(a), math.sqrt(1.0 - a))\n",
    "       \n",
    "    return R * c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caf596fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateStatisticalFeatureMatrix(L1=256, L2=4):\n",
    "    #load trajectories\n",
    "    trajectories = {}\n",
    "    filename = 'data/RandomSample_5_10.csv'\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        ct = ''\n",
    "        cd = ''\n",
    "        tj = []\n",
    "        bar = progressbar.ProgressBar()        \n",
    "        for ln in bar(lines):\n",
    "            pts = ln.replace('\\r\\n','').split(',')\n",
    "            if pts[1] != ct:\n",
    "                if ct == \"\" and pts[0]==\"Driver\":\n",
    "                    continue\n",
    "                if len(tj) >0:\n",
    "                    trajectories[cd+\"|\"+ct] = tj\n",
    "                tj = []\n",
    "                #Driver,ID,Time,Lat,Lon,Speed,Acceleration,RPM,Heading,AccelX,AccelY,AccelZ\n",
    "                tj.append(point(int(pts[2]), float(pts[3]), float(pts[4]), (-1.0 if len(pts[5])==0 else float(pts[5])), (0.0 if len(pts[6])==0 else float(pts[6])), \\\n",
    "                    int(pts[7]), int(pts[8]), float(pts[9]), float(pts[10]), float(pts[11])))\n",
    "                ct = pts[1]\n",
    "                cd = pts[0]\n",
    "            else:\n",
    "                tj.append(point(int(pts[2]), float(pts[3]), float(pts[4]), (-1.0 if len(pts[5])==0 else float(pts[5])), (0.0 if len(pts[6])==0 else float(pts[6])), \\\n",
    "                    int(pts[7]), int(pts[8]), float(pts[9]), float(pts[10]), float(pts[11])))                \n",
    "                \n",
    "        trajectories[cd+\"|\"+ct] = tj\n",
    "    print('Raw Trajectory Data is loaded! |Trajectories|:' + str(len(trajectories)))\n",
    "    \n",
    "    #Generate Basic Features for each trajectory\n",
    "    basicFeatures = {}\n",
    "    bar = progressbar.ProgressBar()\n",
    "    for t in bar(trajectories):\n",
    "        points = trajectories[t]\n",
    "        traj = []\n",
    "        lastAngleSpeed = -1000\n",
    "        lastSpeed = lastAccel = 0\n",
    "        for i in range(1, len(points)):\n",
    "            tuple = []\n",
    "            if 'All' in args.suffix or 'Spd' in args.suffix:  # to include speed in basic features \n",
    "                tuple.append((lastSpeed if points[i].speed==-1.0 else points[i].speed))\n",
    "                lastSpeed = (lastSpeed if points[i].speed==-1.0 else points[i].speed)\n",
    "                \n",
    "            if 'All' in args.suffix or 'Acl' in args.suffix:  # to include acceleration in basic features \n",
    "                tuple.append(points[i].acceleration)\n",
    "                tuple.append(abs(points[i].acceleration - points[i-1].acceleration))\n",
    "            \n",
    "            # calculate gps-based speed and acceleration\n",
    "            if '_gps' in args.suffix:      # to include gps related features (speed and acceleration) in basic features \n",
    "                speed_gps = haversineDistance(points[i-1].lat, points[i-1].lng, points[i].lat, points[i].lng, metric='meters')\n",
    "                tuple.append(speed_gps)\n",
    "                accel_gps = speed_gps-lastSpeed\n",
    "                tuple.append(accel_gps)\n",
    "                tuple.append(abs(accel_gps - lastAccel))\n",
    "                lastSpeed = speed_gps\n",
    "                lastAccel = accel_gps\n",
    "            \n",
    "            if 'All' in args.suffix or 'Ang' in args.suffix:  # to include angular speed in basic features \n",
    "                angularSpeed = returnAngularDisplacement(points[i-1].lat, points[i-1].lng, points[i].lat, points[i].lng)\n",
    "                tuple.append(angularSpeed)\n",
    "                if lastAngleSpeed == -1000: tuple.append(0)\n",
    "                else: tuple.append(abs(angularSpeed-lastAngleSpeed))\n",
    "                lastAngleSpeed = angularSpeed\n",
    "            \n",
    "            if 'All' in args.suffix or 'Rp' in args.suffix:   # to include engine RPM in basic features \n",
    "                tuple.append(points[i].rpm)\n",
    "                tuple.append(abs(points[i].rpm - points[i-1].rpm))\n",
    "            \n",
    "            if 'All' in args.suffix or 'Hd' in args.suffix:  # to include heading in basic features \n",
    "                tuple.append(points[i].heading)\n",
    "                tuple.append(abs(points[i].heading - points[i-1].heading))\n",
    "            \n",
    "            if 'All' in args.suffix or 'XYZ' in args.suffix: # to include accelerometer sensor data in basic features \n",
    "                tuple.append(points[i].accelX)\n",
    "                tuple.append(abs(points[i].accelX - points[i-1].accelX))\n",
    "                tuple.append(points[i].accelY)\n",
    "                tuple.append(abs(points[i].accelY - points[i-1].accelY))\n",
    "                tuple.append(points[i].accelZ)\n",
    "                tuple.append(abs(points[i].accelZ - points[i-1].accelZ))\n",
    "            \n",
    "            traj.append(tuple)        \n",
    "        \n",
    "        basicFeatures[t] = traj\n",
    "    \n",
    "    del trajectories\n",
    "    print('Basic Features are created!')\n",
    "    \n",
    "    \n",
    "    #Generate Statistical Feature Matrix\n",
    "    bar = progressbar.ProgressBar()\n",
    "    start = time.time()\n",
    "    statisticalFeatureMatrix = {}\n",
    "    for t in bar(basicFeatures):\n",
    "        #print 'processing', t      \n",
    "        matricesForTrajectory = []\n",
    "        traj= basicFeatures[t]\n",
    "        LEN = len(traj[0])\n",
    "        ranges = returnSegmentIndexes(L1, len(traj))        \n",
    "        for p in ranges:\n",
    "            if p[1] - p[0] < 256:\n",
    "                continue\n",
    "            matrixForSegment = np.empty((129, LEN*7))\n",
    "            matrixForSegment[0, :] = np.zeros((LEN*7,))\n",
    "            st = p[0]\n",
    "            for timestep in range(1, 129):\n",
    "                en = min(st+L2, p[1])\n",
    "                column = []\n",
    "                for fIdx in range(0, LEN):\n",
    "                    arr = []\n",
    "                    mean = 0.0\n",
    "                    for i in range(int(st),int(en)):            \n",
    "                        mean += traj[i][fIdx]\n",
    "                        arr.append(traj[i][fIdx])      \n",
    "                    arr.sort()\n",
    "                    mean = mean/len(arr)\n",
    "                    column.append(mean) #mean\n",
    "                    column.append(arr[0]) #min\n",
    "                    column.append(arr[len(arr)-1]) #max                    \n",
    "                    column.append(stats.scoreatpercentile(arr, 25)) #25% percentile\n",
    "                    if len(arr)%2 == 0:\n",
    "                        column.append((arr[int(len(arr)/2)] +arr[int((len(arr)/2) -1)]/2.0)) #50% percentile\n",
    "                    else:\n",
    "                        column.append(arr[len(arr)/2]) #50% percentile\n",
    "                    column.append(stats.scoreatpercentile(arr, 75)) #75% percentile\n",
    "                    std = 0\n",
    "                    for a in arr:\n",
    "                        std += (a-mean)**2\n",
    "                    column.append(math.sqrt(std)) #standard deviation\n",
    "                matrixForSegment[timestep, :] = list(column)\n",
    "                st += L2/2            \n",
    "            matricesForTrajectory.append(matrixForSegment)\n",
    "              \n",
    "        # print (len(matricesForTrajectory))\n",
    "        statisticalFeatureMatrix[t] = normalizeStatFeatureMatrix(np.array(matricesForTrajectory))        \n",
    "        \n",
    "      \n",
    "    del basicFeatures    \n",
    "    print(\"statistical features created\")\n",
    "    keys = [k.split(\"|\") for k, v in statisticalFeatureMatrix.items() for i in range(v.shape[0])]\n",
    "    pickle.dump(keys, open('data/RandomSample_5_10.pkl', \"wb\"))\n",
    "    del keys    \n",
    "    np.save('data/RandomSample_5_10.npy', np.vstack(statisticalFeatureMatrix.values()), allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4efe4371",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      " 40% |############################                                            |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Trajectory Data is loaded! |Trajectories|:50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Features are created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91986\\AppData\\Local\\Temp\\ipykernel_20844\\3833826260.py:17: RuntimeWarning: invalid value encountered in divide\n",
      "  statisticalFeatureMatrix = np.nan_to_num(minimum + ((statisticalFeatureMatrix-mins)/(maxs-mins))*r)\n",
      "100% |########################################################################|\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistical features created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\91986\\AppData\\Local\\Temp\\ipykernel_20844\\1342356571.py:143: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  np.save('data/RandomSample_5_10.npy', np.vstack(statisticalFeatureMatrix.values()), allow_pickle=False)\n"
     ]
    }
   ],
   "source": [
    "def returnSegmentIndexes(L1, leng):\n",
    "    ranges = []\n",
    "    start = 0\n",
    "    while True:        \n",
    "        end = min(start+L1, leng-1)\n",
    "        ranges.append([start, end])\n",
    "        start += L1/2\n",
    "        if end == leng-1:\n",
    "            break        \n",
    "    return ranges\n",
    "\n",
    "# to apply min-max normalization\n",
    "def normalizeStatFeatureMatrix(statisticalFeatureMatrix, minimum=0, maximum=10):\n",
    "    r = float(maximum-minimum)\n",
    "    mins = statisticalFeatureMatrix.min((0, 1))\n",
    "    maxs = statisticalFeatureMatrix.max((0, 1))    \n",
    "    statisticalFeatureMatrix = np.nan_to_num(minimum + ((statisticalFeatureMatrix-mins)/(maxs-mins))*r)\n",
    "    return statisticalFeatureMatrix\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    generateStatisticalFeatureMatrix() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
